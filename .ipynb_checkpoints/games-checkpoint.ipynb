{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoframe import get_agent_wrapper_func\n",
    "from evoframe.reward_builders import RewardBuilderGame\n",
    "from evoframe.population_update_builders import PopulationUpdateBuilderStatic\n",
    "from evoframe.selector_function import SelectorFunctionFactory\n",
    "from evoframe import PopulationManager\n",
    "from evoframe.models import FeedForwardNetwork\n",
    "from evoframe.models import ActivationFunctions\n",
    "from evoframe.games import GuessPoint\n",
    "from evoframe.games import Game\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(env):\n",
    "    num_epochs = len(env[\"rewards\"].keys())\n",
    "    xs = np.arange(num_epochs)\n",
    "    ys = [rs[0] for rs in env[\"rewards\"].values()]\n",
    "    plt.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guess the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Game\n",
    "game_creation_function = lambda: GuessPoint(np.array([0.2,0.8,0.5]), np.array([0.4, 0.5, 10]))\n",
    "\n",
    "# Model\n",
    "layer_sizes = [3, 5, 3]\n",
    "get_model_func = lambda: FeedForwardNetwork(layer_sizes, ActivationFunctions.get_sigmoid(), ActivationFunctions.get_id())\n",
    "\n",
    "# Game-Model interface\n",
    "predict_func = lambda model, inputs: model.predict(inputs)\n",
    "agent_wrapper_func = get_agent_wrapper_func(predict_func)\n",
    "\n",
    "# Reward function and update env function\n",
    "reward_function, update_env_f = RewardBuilderGame() \\\n",
    ".with_game_creation_function(game_creation_function) \\\n",
    ".with_agent_wrapper_func(agent_wrapper_func) \\\n",
    ".get()\n",
    "\n",
    "# Update population function\n",
    "mutation_perc = 0.6\n",
    "crossover_perc = 0.3\n",
    "copy_perc = 0.1\n",
    "get_new_pop_f = PopulationUpdateBuilderStatic() \\\n",
    ".add_operator(\"es_1_mutation\", mutation_perc, 0.3, 0.3) \\\n",
    ".add_operator(\"es_2_crossover\", crossover_perc, 0.8) \\\n",
    ".add_operator(\"es_1_copy\", copy_perc) \\\n",
    ".add_selector_f(SelectorFunctionFactory.get_geometric_selector_function(0.3)) \\\n",
    ".get()\n",
    "\n",
    "# Population manager\n",
    "pop_size = 500\n",
    "pm = PopulationManager(pop_size, get_model_func, reward_function, update_env_f, get_new_pop_f)\n",
    "\n",
    "# Run population manager\n",
    "num_epochs = 10\n",
    "last_pop, env = pm.run(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rewards(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guess the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuessFunction(Game):\n",
    "    \"\"\"This game consists in learning a function from n dimensions to m dimensions, evaluating points\n",
    "        on a grid.\n",
    "\n",
    "        1 player game.\n",
    "\n",
    "        Agent interface:\n",
    "        - input: n-dimensional np.array filled with values\n",
    "        - output: m-dimensional np.array filled with values\n",
    "        \"\"\"\n",
    "    def __init__(self, func, input_dim, input_domains, sample_every):\n",
    "        self.func = func\n",
    "        self.input_dim = input_dim # input dimension\n",
    "        self.input_domains = input_domains # domain for each scalar in the input vector\n",
    "        self.sample_every = sample_every # sampling bin for each scalar in the input vector\n",
    "\n",
    "    def play(self, agent):\n",
    "        error = 0\n",
    "        ranges = []\n",
    "        for i in range(self.input_dim):\n",
    "            input_domain = self.input_domains[i]\n",
    "            sample_every = self.sample_every[i]\n",
    "            ranges.append(np.arange(input_domain[0], input_domain[1], sample_every))\n",
    "        for input_tuple in product(*ranges):\n",
    "            input_array = np.array(input_tuple)\n",
    "            predictions = agent.predict(input_array)\n",
    "            error += np.sum(np.square(self.func(input_array) - predictions))\n",
    "        reward = -error\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Game\n",
    "game_func = lambda i: np.array([2*i[0]-3*i[1]+4, i[1]-8*i[2]-5])\n",
    "input_dim = 3\n",
    "input_domains = [(-1,1),(-1,1),(3,7)]\n",
    "sample_every = [0.1, 0.1, 0.3]\n",
    "game_creation_function = lambda: GuessFunction(game_func, input_dim, input_domains, sample_every)\n",
    "\n",
    "# Model\n",
    "layer_sizes = [3, 5, 2]\n",
    "get_model_func = lambda: FeedForwardNetwork(layer_sizes, ActivationFunctions.get_arctan(), ActivationFunctions.get_id())\n",
    "\n",
    "# Game-Model interface\n",
    "predict_func = lambda model, inputs: model.predict(inputs)\n",
    "agent_wrapper_func = get_agent_wrapper_func(predict_func)\n",
    "\n",
    "# Reward function and update env function\n",
    "reward_function, update_env_f = RewardBuilderGame() \\\n",
    ".with_game_creation_function(game_creation_function) \\\n",
    ".with_agent_wrapper_func(agent_wrapper_func) \\\n",
    ".get()\n",
    "\n",
    "# Update population function\n",
    "get_new_pop_f = PopulationUpdateBuilderStatic() \\\n",
    ".add_operator(\"es_1_mutation\", 0.6, 0.3, 0.5) \\\n",
    ".add_operator(\"es_2_crossover\", 0.3, 0.1) \\\n",
    ".add_operator(\"es_1_copy\", 0.1) \\\n",
    ".add_selector_f(SelectorFunctionFactory.get_geometric_selector_function(0.3)) \\\n",
    ".get()\n",
    "\n",
    "# Population manager\n",
    "pop_size = 30\n",
    "pm = PopulationManager(pop_size, get_model_func, reward_function, update_env_f, get_new_pop_f)\n",
    "\n",
    "# Run population manager\n",
    "num_epochs = 100\n",
    "last_pop, env = pm.run(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rewards(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([np.random.rand(1) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array([0.5,0.5,5])\n",
    "last_pop[0].predict(test_array), game_func(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play Tris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAYER_1 = 1\n",
    "PLAYER_2 = -1\n",
    "EMPTY = 0\n",
    "DRAW = 0\n",
    "CONTINUE = 2\n",
    "PLAYERS = [PLAYER_1, PLAYER_2]\n",
    "\n",
    "class Tris(Game):\n",
    "    def __init__(self):\n",
    "        self.board = np.array([np.array([EMPTY for i in range(3)]) for j in range(3)])\n",
    "        \n",
    "    def check_win(self):\n",
    "        # check rows\n",
    "        board = self.board\n",
    "        for row in board:\n",
    "            for player in PLAYERS:\n",
    "                if np.all(np.equal(row, np.full(3, player))):\n",
    "                    return player\n",
    "        \n",
    "        # check cols\n",
    "        board = self.board.transpose()\n",
    "        for row in board:\n",
    "            for player in PLAYERS:\n",
    "                if np.all(np.equal(row, np.full(3, player))):\n",
    "                    return player\n",
    "                \n",
    "        # check diagonals\n",
    "        diags = []\n",
    "        diags.append(np.array([board[i][i] for i in range(3)]))\n",
    "        diags.append(np.array([board[i][3 - i - 1] for i in range(3)]))\n",
    "        for row in diags:\n",
    "            for player in PLAYERS:\n",
    "                if np.all(np.equal(row, np.full(3, player))):\n",
    "                    return player\n",
    "        \n",
    "        # check draw\n",
    "        exist_empty = False\n",
    "        for row in self.board:\n",
    "            for cell in row:\n",
    "                if cell == EMPTY:\n",
    "                    exist_empty = True\n",
    "        if not exist_empty:\n",
    "            return DRAW\n",
    "        \n",
    "        return CONTINUE\n",
    "    \n",
    "    def extract_move(self, prediction):\n",
    "        highest_value = -10\n",
    "        highest_value_index = -1\n",
    "        for i,pred in enumerate(prediction):\n",
    "            if self.board[i//3][i%3] == EMPTY and pred > highest_value:\n",
    "                highest_value = pred\n",
    "                highest_value_index = i\n",
    "        return highest_value_index\n",
    "    \n",
    "    def do_move(self, move, player):\n",
    "        self.board[move//3][move%3] = player\n",
    "        \n",
    "    def opposite_board(self):\n",
    "        return np.array([np.array([PLAYER_2 if self.board[row][col] == PLAYER_1\n",
    "                                   else PLAYER_1 if self.board[row][col] == PLAYER_2\n",
    "                                   else EMPTY for col in range(3)]) for row in range(3)])\n",
    "    \n",
    "    def play(self, agent_1, agent_2, interactive=False):\n",
    "        player_turn = np.random.choice(PLAYERS)\n",
    "        \n",
    "        if interactive:\n",
    "            self.print_board() \n",
    "        \n",
    "        result = self.check_win()\n",
    "        while result == CONTINUE:\n",
    "            if player_turn == PLAYER_1:\n",
    "                prediction = agent_1.predict(self.board)\n",
    "            else:\n",
    "                prediction = agent_2.predict(self.opposite_board())\n",
    "              \n",
    "            move = self.extract_move(prediction)\n",
    "            self.do_move(move, player_turn)\n",
    "            \n",
    "            if interactive:\n",
    "                self.print_board()\n",
    "            \n",
    "            if player_turn == PLAYER_1:\n",
    "                player_turn = PLAYER_2\n",
    "            else:\n",
    "                player_turn = PLAYER_1\n",
    "                \n",
    "            result = self.check_win()\n",
    "            \n",
    "        if interactive:\n",
    "                self.print_board()    \n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def print_board(self):\n",
    "        for row in self.board:\n",
    "            for cell in row:\n",
    "                print(cell, end=\" \")\n",
    "            print(\"\")\n",
    "        print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoframe.reward_builders.reward_builder_game import TournamentMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Game\n",
    "game_creation_function = lambda: Tris()\n",
    "\n",
    "# Model\n",
    "layer_sizes = [9, 5, 5, 9]\n",
    "get_model_func = lambda: FeedForwardNetwork(layer_sizes, ActivationFunctions.get_arctan(), ActivationFunctions.get_id())\n",
    "\n",
    "# Game-Model interface\n",
    "def predict_func(model, inputs):\n",
    "    # In Tris, 'inputs' is a 3x3 np.array, thus we must flatten it to a 9x1 np.array\n",
    "    # output is a 9x1 vector, where the cell with highest value corresponding\n",
    "    # to a valid move will be the chosen move\n",
    "    return model.predict(inputs.flatten())[0]\n",
    "agent_wrapper_func = get_agent_wrapper_func(predict_func)\n",
    "\n",
    "# Reward function and update env function\n",
    "# Since Tris is a two-players game, we can compute the reward with a tournament against the current generation\n",
    "reward_function, update_env_f = RewardBuilderGame() \\\n",
    ".with_game_creation_function(game_creation_function) \\\n",
    ".with_agent_wrapper_func(agent_wrapper_func) \\\n",
    ".with_competitive_tournament(TournamentMode.VS_BEST_OF_EACH_GEN) \\\n",
    ".with_keep_only(30) \\\n",
    ".get()\n",
    "\n",
    "# Update population function\n",
    "get_new_pop_f = PopulationUpdateBuilderStatic() \\\n",
    ".add_operator(\"es_1_mutation\", 0.6, 0.3, 0.5) \\\n",
    ".add_operator(\"es_2_crossover\", 0.3, 0.1) \\\n",
    ".add_operator(\"es_1_copy\", 0.1) \\\n",
    ".add_selector_f(SelectorFunctionFactory.get_geometric_selector_function(0.3)) \\\n",
    ".get()\n",
    "\n",
    "# Population manager\n",
    "pop_size = 50\n",
    "pm = PopulationManager(pop_size, get_model_func, reward_function, update_env_f, get_new_pop_f)\n",
    "\n",
    "# Run population manager\n",
    "num_epochs = 300\n",
    "last_pop = pm.run(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentHuman:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, board):\n",
    "        move = int(input(\"Select move: \"))\n",
    "        prediction = [1 if i == move else 0 for i in range(9)]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game = Tris()\n",
    "game.play(agent_wrapper_func(last_pop[0]), AgentHuman(), interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
