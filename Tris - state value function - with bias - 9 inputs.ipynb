{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoframe.reward_builders import RewardBuilderGame\n",
    "from evoframe.population_update_builders import PopulationUpdateBuilderStatic\n",
    "from evoframe.selector_function import SelectorFunctionFactory\n",
    "from evoframe import EvolutionBuilder\n",
    "from evoframe.models import FeedForwardNetwork\n",
    "from evoframe.models import ActivationFunctions\n",
    "from evoframe.games import Game\n",
    "from evoframe import get_agent_wrapper_func\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from evoframe.experiment_results import *\n",
    "from evoframe.utility import clean_experiment_directory\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoframe.reward_builders.reward_builder_game import TournamentMode\n",
    "from evoframe.games import Tris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game\n",
    "game_creation_func = lambda context: Tris()\n",
    "\n",
    "# Model\n",
    "layer_sizes = [9, 6, 3, 1]\n",
    "get_model_func = lambda: FeedForwardNetwork(layer_sizes, ActivationFunctions.get_sigmoid(), ActivationFunctions.get_sigmoid())\n",
    "\n",
    "# Game-Model interface\n",
    "def predict_func(model, game):\n",
    "    available_actions = game.get_available_actions()\n",
    "    vs = []\n",
    "    for a in available_actions:\n",
    "        next_state = game.get_next_state(a)\n",
    "        vs.append(model.predict(next_state.flatten())[0])\n",
    "    i_max = np.array(vs).argmax()\n",
    "    best_action = available_actions[i_max]\n",
    "    return best_action\n",
    "agent_wrapper_func = get_agent_wrapper_func(predict_func)\n",
    "\n",
    "# Reward function and update env function\n",
    "# Since Tris is a two-players game, we can compute the reward with a tournament against the current generation\n",
    "keep_only = 30\n",
    "reward_func, get_context_func = RewardBuilderGame() \\\n",
    ".with_game_creation_func(game_creation_func) \\\n",
    ".with_agent_wrapper_func(agent_wrapper_func) \\\n",
    ".with_competitive_tournament(TournamentMode.VS_BESTS_RANDOM) \\\n",
    ".with_keep_only(keep_only) \\\n",
    ".get()\n",
    "\n",
    "# Update population function\n",
    "get_new_pop_func = PopulationUpdateBuilderStatic() \\\n",
    ".add_operator(\"es_1_copy\", 0.1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.05, 0.1, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.05, 0.2, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.05, 0.3, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.1, 0.1, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.1, 0.2, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.1, 0.3, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.2, 0.1, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.2, 0.2, 1) \\\n",
    ".add_operator(\"es_n_rewards_gradient_and_mutation\", 0.1, 0.2, 0.3, 1) \\\n",
    ".add_selector_func(SelectorFunctionFactory.get_geometric_selector_function(0.3)) \\\n",
    ".get() # learning rate, sigma, keep perc \n",
    "\n",
    "# Evolution function\n",
    "evolution_func = EvolutionBuilder() \\\n",
    "    .with_get_model_func(get_model_func) \\\n",
    "    .with_reward_func(reward_func) \\\n",
    "    .with_get_new_pop_func(get_new_pop_func) \\\n",
    "    .with_get_context_func(get_context_func) \\\n",
    "    .get()\n",
    "\n",
    "pop_size = 100\n",
    "num_epochs = 10\n",
    "experiment_name = \"tris_gradient_and_mutation\"\n",
    "clean_experiment_directory(experiment_name)\n",
    "evolution_func(experiment_name, pop_size, num_epochs, num_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 100\n",
    "num_epochs = 10\n",
    "experiment_name = \"tris_gradient_and_mutation\"\n",
    "def predict_func(model, game):\n",
    "    available_actions = game.get_available_actions()\n",
    "    vs = []\n",
    "    for a in available_actions:\n",
    "        next_state = game.get_next_state(a)\n",
    "        vs.append(model.predict(next_state.flatten())[0])\n",
    "    i_max = np.array(vs).argmax()\n",
    "    best_action = available_actions[i_max]\n",
    "    return best_action\n",
    "agent_wrapper_func = get_agent_wrapper_func(predict_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rewards(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_best_fnn_weights,\n",
    "         experiment_name=fixed(experiment_name),\n",
    "         epoch=widgets.IntSlider(min=1, max=num_epochs, step=1, value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "def show_predictions(model, inp):\n",
    "    game = Tris()\n",
    "    game.board = inp\n",
    "    out = np.array(model.predict(game))\n",
    "    for r,row in enumerate(game.board):\n",
    "        for c,cell in enumerate(row):\n",
    "            if cell != 0:\n",
    "                out[r*3 + c] = -100000\n",
    "    out = out.reshape((3,3))\n",
    "    shape = out.shape\n",
    "    data = [(row+1, col+1, out[row][col]) for row in range(shape[0]) for col in range(shape[1])]\n",
    "    columns = [\"neuron_input\", \"neuron_output\", \"value\"]\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return px.density_heatmap(df, x=\"neuron_output\", y=\"neuron_input\", z=\"value\",\n",
    "                                         histfunc=\"sum\", color_continuous_scale=\"RdYlGn\", range_color=(-2,2),\n",
    "                                         nbinsx=shape[1], nbinsy=shape[0],\n",
    "                                         range_x=(0.5, shape[1]+0.5), range_y=(0.5, shape[0]+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_input_func():\n",
    "    return np.array([[np.random.choice([-1,0,1]) for i in range(3)] for j in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = agent_wrapper_func(pickle_load_best_model_of_epoch(experiment_name, num_epochs, pop_size))\n",
    "inp = get_random_input_func()\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(inp[2-i][j], end=\" \")\n",
    "    print(\"\")\n",
    "show_predictions(model, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavioural_differences(experiment_name, get_random_input_func, mode=\"first_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavioural_differences(experiment_name, get_random_input_func, mode=\"last_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavioural_variances_to_input(experiment_name, get_random_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = plot_params_statistics(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_operators_statistics_means(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_operators_statistics_max(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tournament(experiment_name, agent_wrapper_func, Tris, 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentHuman:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, game):\n",
    "        move = int(input(\"Select move: \"))\n",
    "        prediction = [1 if i == move else 0 for i in range(9)]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Tris()\n",
    "game.play(AgentHuman(), agent_wrapper_func(pickle_load_best_model_of_epoch(experiment_name, num_epochs, pop_size)), interactive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
